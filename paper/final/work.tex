\chapter{Теоретические сведения.}

\section{Байесовский подход.}

\subsection{Основы байесовской статистики.}

Перед тем, как приступить к сетям, вспомним основы байесовской статистики.

Байесовская статистика противопоставляется частотной статистике, как альтернатива. Основное отличие в двух подходах состоит в том,
 что в байесовской статистике вероятность интерпретируется, как степень уверенности в истинности суждения. Другими словами, как мера незнания или неопределённости.
 В частотной статистике вероятность определяется как частота события. Байесовскую вероятность ещё иногда называют <<логической>> вероятностью, поскольку
 её проще применять в реальных задачах.

Байесовский подход же к оценке параметров заключается в утверждении, что априрорные знания влияют на апостериорные знания. Данное утверждение наиболее ярко видно в формуле Байеса:
$$P(H | D) = \frac{P(D | H)P(H)}{P(D)} = \frac{P(D | H)P(H)}{\int_{\mathcal{H}} P(D | \widetilde{H})P(\widetilde{H}) d\widetilde{H}}$$
$$P(H | D) \propto P(D | H)P(H)$$

В данной формуле $H$~---~некоторая гипотеза, вероятность которой мы хотим узнать, при помощи известных данных $D$. $P(H)$~---~это априорная вероятность или априорные знания о нашей
 гипотезе, которые мы знаем до того, как пронаблюдали данные $D$. Распределение вероятности $P(D | H)$ называется правдоподобием наблюдаемых данных $D$, если гипотеза верна.

Байесовские статические методы использует Теорему Байеса для вычисления и обновления вероятности после получения новых данных.

\subsection{Байесовский подход к оценке параметров.}

Теперь перейдем к задаче оценке параметров статических(вероятностных) моделей. К таким моделям можно отнести почти все модели машинного обучения, нейронные сети, марковские цепи и др.

В общем случае обозначим за $a_{\theta}(x)$~---~статическую модель из параметризованного семейства $\{a_{\theta}(x) : \theta \in \Theta\}$, где $\theta$~---~параметры модели. В случае
 линейной регрессии $y = w^T x + b$, $\theta = \{w, b\}$; для нейронных сетей $\theta$~---~веса промежуточных слоёв; для марковских цепях $\theta$ --- вероятности на рёбрах и т.д.

Когда мы занимаемся выбором модели $a_{\theta}(x)$, которая наилучшим образом(в некоторым смысле) описывают неизвестную закономерость в данных, то мы занимаемся подбором параметров $\theta$.
 В классическом подходе мы хотим найти \textit{точечную оценку} на параметры $\theta$, то есть найти значения параметров $\widehat{\theta}$, при котором качество нашей статической модели будет наилучшим.
 Тут важно отметить, что нас интересует единственное такое оптимальное значение, даже если их может быть несколько. В этом и заключается точечный подход к оценке параметров.


\chapter{Виды нейронных сетей.}

\section{Детерминированные нейронные сети.}

Сначала напомним, что такое обычные(детерминированные) нейронные сети и как они обучаются.

Основная задача обычных искусственных нейронных сетей($ANN$) в том, чтобы аппроксимировать некоторую зависимость выхода $y$ от
 входа $x$: $y = \Phi(x)$. Зависимость $\Phi(x)$ аппроксимируем через композицию последовательных преобразований.

Для простоты будем рассматривать обычные \textit{полносвязные} сети со входом $x$,
 скрытыми(промежуточными) состояниями слоёв $\bm{h_i}$, функциями активации $a_i(\cdot)$ и выходом $y$:
$$\bm{h_0} = \bm{x}$$
$$\bm{h_i} = a_i(\bm{W_i} \cdot h_{i-1} + \bm{b_i}), i = \overline{1...n}$$
$$\bm{h_n} = \widehat{y}$$
$$L = \mathcal{L}(\widehat{y}, y),$$ где $\mathcal{L}(\cdot, \cdot)$ - функция ошибки.

Обозначим параметры модели на $i$-ом слое $\bm{\theta_i} = (\bm{W_i}, \bm{b_i})$, а параметры всей модели через $\bm{\Theta} = \{\bm{\theta_i} :~i~=~\overline{1...n}\}$.
Чаще всего нейронные сети принято рассматривать, как вычислительный граф/граф вычислений.
 Такой подход удобен с инженерной точки зрения, поскольку позволяет воспользоваться инструментом автоматического
 дифференцирования, и используется во всех современных фреймоворках: PyTorch, TensorFlow и прочие.
 Граф вычислений является ациклическим ориентированным графом, составленным из вершин-переменных и вершин-операций(Рисунок~\ref{fig:ANN}).
\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\linewidth]{ANN.png}
    \caption{\textit{Полносвязная} сеть в виде графа вычислений}
    \label{fig:ANN}
\end{figure}

Далее будем называть модели, основанные на графах вычислений, --- графовыми моделями. Графы вычислений могут разных типов:
 статическими/динамическими, детерминированными/вероятностными и т.д. Для обучения/настройки параметров детерминированных графовых моделей
 используется метод \textit{обратного распространения ошибки(back propagation)}, который широко используется в современном мире. Вкратце напомним алгоритм:

После прямого выполнения графа(\textit{forward pass}), то есть в соответствии с направлениями рёбер на выходе мы получаем
 $L$ -значение функции ошибки, которые в зависимости от задач мы хотим либо минимизировать, либо максимизировать. Для этого
 мы пользуемся градиентными методами оптимизации, что требует вычисление градиентов $\frac{dL}{d W_i}, \frac{dL}{d b_i}$ по нашим параметрам модели, где $i = \overline{1,n}$.
 В общем случае это трудная задача, однако в случае детерминированных графовых моделей мы можем использовать цепное правило(\textit{chain rule}) для того, чтобы последовательно
 проталкивать градиенты, начиная с концевой вершины, содержащей $L$.

 Например, для подсчёта градиентов $\frac{dL}{d W_n}, \frac{dL}{d b_n}$ мы представим его в виде
 $$\frac{dL}{d W_n} = \frac{dL}{d h_n} \cdot \frac{d h_n}{d W_n}$$
 $$\frac{dL}{d b_n} = \frac{dL}{d h_n} \cdot \frac{d h_n}{d b_n}$$

Аналогично для всех остальных параметров модели мы будем проталкивать накопленный с концевой вершины градиент до соответствующих вершин и
 с помощью этого градиента высчитывать градиент по параметрам модели. Схему работы алгоритма обратного распространения ошибки
 можно увидеть на Рисунок~\ref{fig:ANN_back_prop}.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\linewidth]{ANN_back_prop.png}
    \caption{Обратное распространение ошибки по графу вычислений детерминированной полносвязной сети}
    \label{fig:ANN_back_prop}
\end{figure}

Однако детерминированные нейронные сети обладают несколькими проблемами:
\begin{itemize}
    \item Переобучение.
    \item Низкая интерпретируемость.
    \item Завышенная/заниженная уверенность модели в предсказаниях, даже если они неверные.
    \item Низкий уровень откалиброванности модели.
\end{itemize}

Указанные проблемы попытаемся решить с помощью байесовского подхода к нейронным сетям, который
 рассмотрим далее.

\section{Байесовские нейронные сети.}
\subsection{Вероятностные графы вычислений.}

Перед тем, как приступить к байесовским нейронным сетям, рассмотрим \textit{вероятностные графы вычислений}, на которых основаны
 байесовские сети. В литературе также часто вместо названия \textit{вероятностные графы вычислений} встречается \textit{вероятностные графические модели}.
 Второе название является более общим, в то время как первое более специфично именно для байесовских нейронных сетей.
 Такие графы вычислений широко используются и известны достаточно давно. Они лежат в основе, например,
 Марковских цепей, которые ранее активно использовались в различных задачах машинного предсказания, распознавания образов и т.п.

Основная мотивация в использовании вероятностного подхода состоит в том, что в реальном мире мы чаще имеем дело с неопределённостью в данных и знаниях
 и не можем детерминированно описать все приходящие переменные для решения задачи. Для решения проблем с неопределённостью
 можно попробовать собрать большие объёмы данных для того, чтобы попытаться "понять" эту неопределённость. С другой стороны
 мы можем использовать байесовский подход, который напрямую оперирует с неопределённостью.

Рассмотрим структуру \textit{вероятностных графовых моделей}. В отличие от детерминированных моделей в граф добавляются вершины
 со случайными переменными. Таким образом в нашем совместно существуют детерминированные вершины и случайные (Рисунок \ref{fig:PGM_example}). Стоит отметить,
 что после вступления в контакт детерминированных переменных и случайных, весь дальнейший результат будет случайным.
 При работе с такими моделями нужно различать \textit{наблюдаемые} и \textit{скрытые/латентные} переменные.
 Различия в этих двух понятиях естественны: в реальной жизни у нас есть некоторые известные данные и те, которые мы не может измерить явно,
 а лишь вычислить в результате работы модели.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\linewidth]{PGM_example.png}
    \caption{Вероятностная графическая модель. Здесь круги с пунктирной границей являются сэмплируемыми случайными величинами. Зелёным цветом обозначены наблюдаемые случайные переменные.}
    \label{fig:PGM_example}
\end{figure}

Стоит сделать замечание, что детерминированные переменные также можно представить,
 как случайные величины с $\delta$-функцией плотности распределения $\delta(\cdot)$,
 где $\delta(\cdot)$ --- $\delta$-функция Дирака. Данный факт позволяет рассматривать все вершины
 в вероятностной графовой модели, как случайные.

Введём более строгое определение. Пусть $(x_1, x_2, ..., x_n)$ - множество случайных величин, представляющих вершины
 ориентированного графа. Тогда \textit{вероятностная графическая модель} --- это семейство условных распределений $p(x_1 | ...)$, $p(x_2 | ...)$ и т.д. над
 данными случайными величинами $x_1, x_2, x_3, ..., x_n$.

В случае графовых моделей каждая случайная величина $x_i$ зависит не от всех других случайных
 величин, а лишь от некоторого множество её предков $ancestors(x_i)$.
 Таким образом мы можем вычислить полную условную плотность величины $x_i$ так:
$$p(x_i | x_n, x_{n-1}, ... x_1) = p(x_i | ancestors(x_i))$$

Используя \textit{цепное правило} для совместного распределения $p(x_1, x_2, ..., x_n)$ мы можем расписать его
 через частные распределения и условные:
$$p(x_1, x_2, ..., x_n) = p(x_1) p(x_2 | x_1) p(x_3 | x_2, x_1) ... p(x_n | x_{n-1}, ..., x_1)$$

Выбирая порядок множителей справа удобным образом мы можем вычислить совместное распределение.

Подобные \textit{вероятностные графические модели} позволяют узнавать неочевидные взаимосвязи в данных, если в качестве
 вершин принять, например, признаки из какого-нибудь набора данных. При достаточном времени, потраченном на составлении связей в данном графе,
 аналитик данных способен в удобной форме отлавливать закономерности и проверять гипотезы о распределении данных. Также возможно их использование в
 системном или бизнес анализах, однако придётся потратить больше времени для дизайна нашего графа, поскольку мы можем столкнуться с не числовыми вершинами, а, например, событийными.

Другая полезная особенность таких моделей в том, что вместо какого-то конкретного значения интересующей нас величины мы получаем её распределение(Рисунок \ref{fig:PGM_pdf}).
 Это даёт сильно больше информации, чем одно значение и позволяет оценивать \textit{риски}, связанные с этой величиной. Существует много задач, где определение рисков важнее
 какого-то одного ответа. Примеры: задача кредитного скоринга, большинство задач по работе с финансами(определение стоимости ценных бумаг, курса валют и т.д.), задачи в области медицины
 и здравоохранения, транспорт на автопилоте и т.п.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\linewidth]{PGM_pdf.png}
    \caption{Та же графическая модель, но с видимыми распределениями значений в вершинах. Детерминированные вершины имеют $\delta$-функцию распределения.}
    \label{fig:PGM_pdf}
\end{figure}

Существуют несколько инструментов для работы с такими моделями: Bayes Net Toolbox ($\verb|MATLAB|$), pgmpy ($\verb|Python|$) и др.

\subsection{Байесовские нейронные сети.}
